{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mlc-ai/notebooks/blob/main/2_tensor_program_abstraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing FP32 vs Int8 latency\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GEqpO14Lf0Lq"
   },
   "source": [
    "Use the Matrix multiplication program from the Machine Learning Compiler course to explore the FP32 vs Int8 optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9ExHE3BfYYv",
    "outputId": "0d82d527-8051-4bc3-c3a7-0cbb12d9bcce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "    ):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> m, n, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                v_m, v_n, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [m, n, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_m, v_k], B[v_k, v_n])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[v_m, v_n])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int8(<span style=\"color: #008000\">0</span>)\n",
       "                C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_m, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_n]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 1.665116\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "# The default tensor type in tvm\n",
    "# dtype = \"float32\"\n",
    "dtype = \"int8\"\n",
    "\n",
    "target = \"llvm -mcpu=skylake\"\n",
    "dev = tvm.device(target, 0)\n",
    "\n",
    "# Algorithm\n",
    "k = te.reduce_axis((0, K), \"k\")\n",
    "A = te.placeholder((M, K), dtype, name=\"A\")\n",
    "B = te.placeholder((K, N), dtype, name=\"B\")\n",
    "C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\"C\")\n",
    "\n",
    "# Default schedule\n",
    "func = te.create_prim_func([A, B, C])\n",
    "func = func.with_attr(\"global_symbol\", \"main\")\n",
    "ir_module = IRModule({\"main\": func})\n",
    "ir_module.show()\n",
    "\n",
    "\n",
    "func = tvm.build(ir_module, target)  # The module for CPU backends.\n",
    "\n",
    "a = tvm.nd.array(np.random.rand(M, K).astype(dtype), dev)\n",
    "b = tvm.nd.array(np.random.rand(K, N).astype(dtype), dev)\n",
    "c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swj-gMz-1vBE"
   },
   "source": [
    "We can transform the loop access pattern to make it more cache friendly. Let us use the following schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W60q68KRgdNL",
    "outputId": "b49a101e-5148-4cf0-df88-0e112e741381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.tir.schedule.schedule.Schedule'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "    ):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> m_0, n_0, k, m_1, n_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                v_m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1024</span>, m_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> m_1)\n",
       "                v_n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1024</span>, n_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> n_1)\n",
       "                v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(<span style=\"color: #008000\">1024</span>, k)\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_m, v_k], B[v_k, v_n])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[v_m, v_n])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int8(<span style=\"color: #008000\">0</span>)\n",
       "                C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_m, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_n]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after transformation: 0.040189\n"
     ]
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(ir_module)\n",
    "print(type(sch))\n",
    "block_c = sch.get_block(\"C\")\n",
    "# Get loops surronding the block\n",
    "(y, x, k) = sch.get_loops(block_c)\n",
    "block_size = 32\n",
    "yo, yi = sch.split(y, [None, block_size])\n",
    "xo, xi = sch.split(x, [None, block_size])\n",
    "\n",
    "sch.reorder(yo, xo, k, yi, xi)\n",
    "sch.mod.show()\n",
    "\n",
    "func = tvm.build(sch.mod, target=\"llvm -mcpu=skylake\")  # The module for CPU backends.\n",
    "\n",
    "c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "print(\"after transformation: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1RQGOBjn4w_"
   },
   "source": [
    "Try to change the value of bn to see what performance you can get. In pratice, we will leverage an automated system to search over a set of possible transfromations to find an optimal one."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2-tensor-program-abstraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f9f1961f3cd2aa30cee50c488a9e053b355d17c1c2c8f287ecc8b2b5b31144d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
