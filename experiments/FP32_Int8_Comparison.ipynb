{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mlc-ai/notebooks/blob/main/2_tensor_program_abstraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing FP32 vs Int8 latency\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GEqpO14Lf0Lq"
   },
   "source": [
    "Use the Matrix multiplication program from the Machine Learning Compiler (MLC) course to explore the FP32 vs Int8 optimizations. The goal is to explore how the default schedule can be improved by splitting the inner loop of the comptute block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9ExHE3BfYYv",
    "outputId": "0d82d527-8051-4bc3-c3a7-0cbb12d9bcce"
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "\n",
    "# Dimensions of the matrices\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "# Update the flag below for the desired HW target\n",
    "target = \"llvm -mcpu=skylake\"\n",
    "dev = tvm.device(target, 0)\n",
    "\n",
    "# Iterate over the data types, first create the result dictionaries\n",
    "result_fp_dict = dict()\n",
    "result_int_dict = dict()\n",
    "\n",
    "for dtype in [\"float32\", \"int8\"]:\n",
    "    # Algorithm\n",
    "    k = te.reduce_axis((0, K), \"k\")\n",
    "    A = te.placeholder((M, K), dtype, name=\"A\")\n",
    "    B = te.placeholder((K, N), dtype, name=\"B\")\n",
    "    C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\"C\")\n",
    "\n",
    "    # Default schedule\n",
    "    func = te.create_prim_func([A, B, C])\n",
    "    func = func.with_attr(\"global_symbol\", \"main\")\n",
    "    ir_module = IRModule({\"main\": func})\n",
    "    \n",
    "    func = tvm.build(ir_module, target)  # The module for CPU backends.\n",
    "\n",
    "    a = tvm.nd.array(np.random.rand(M, K).astype(dtype), dev)\n",
    "    b = tvm.nd.array(np.random.rand(K, N).astype(dtype), dev)\n",
    "    c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
    "    func(a, b, c)\n",
    "\n",
    "    evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "    print(\"Data Type:\", dtype.rjust(7, ' '), \"   Baseline latency:  %f\" % evaluator(a, b, c).mean)\n",
    "\n",
    "    for block_size in [8, 16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "        # Now change the schedule taking into consideration the cache\n",
    "        sch = tvm.tir.Schedule(ir_module)\n",
    "        block_c = sch.get_block(\"C\")\n",
    "        # Get loops surronding the block\n",
    "        (y, x, k) = sch.get_loops(block_c)\n",
    "        yo, yi = sch.split(y, [None, block_size])\n",
    "        xo, xi = sch.split(x, [None, block_size])\n",
    "\n",
    "        sch.reorder(yo, xo, k, yi, xi)\n",
    "\n",
    "        func = tvm.build(sch.mod, target=\"llvm -mcpu=skylake\")  # The module for CPU backends.\n",
    "\n",
    "        c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
    "        func(a, b, c)\n",
    "\n",
    "        evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "        result = evaluator(a, b, c).mean\n",
    "        print(\"Splitting tensors into\", str(block_size).rjust(4, ' '),\n",
    "              \"word blocks: %.4f\" % result)\n",
    "        \n",
    "             # Create a result dictionary for both FP and int8\n",
    "        if dtype == \"float32\":\n",
    "            result_fp_dict.update({block_size:result})\n",
    "        elif dtype == \"int8\":\n",
    "            result_int_dict.update({block_size:result})\n",
    "        else:\n",
    "            print(\"Something went wrong\")\n",
    "            pass\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the best schedules for both FP32 and Int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = sorted(result_fp_dict.items(), key=lambda x:x[1])[1]\n",
    "print(\"Best FP32 is block_size\", str(best[0]).rjust(4, ' '),\n",
    "      \"with latency %.4f\" % best[1])\n",
    "best = sorted(result_int_dict.items(), key=lambda x:x[1])[1]\n",
    "print(\"Best Int8 is block_size\", str(best[0]).rjust(4, ' '),\n",
    "      \"with latency %.4f\" % best[1])\n",
    "block_size = int(best[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what the optimization did for the best schedule compared to the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Int8 schedule\")\n",
    "ir_module.show()\n",
    "\n",
    "print(\"Reordered schedule:\")\n",
    "sch = tvm.tir.Schedule(ir_module)\n",
    "block_c = sch.get_block(\"C\")\n",
    "# Get loops surronding the block\n",
    "(y, x, k) = sch.get_loops(block_c)\n",
    "yo, yi = sch.split(y, [None, block_size])\n",
    "xo, xi = sch.split(x, [None, block_size])\n",
    "sch.reorder(yo, xo, k, yi, xi)\n",
    "\n",
    "sch.mod.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2-tensor-program-abstraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f9f1961f3cd2aa30cee50c488a9e053b355d17c1c2c8f287ecc8b2b5b31144d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
